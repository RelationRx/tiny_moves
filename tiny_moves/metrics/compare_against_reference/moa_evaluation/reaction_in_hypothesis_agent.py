import json

from autogen import AssistantAgent

from tiny_moves.representations.structured_representations.QA import TernaryAnswerWithEvidence
from tiny_moves.utils.llm_configs.llm_configs import gpt4o_ternary_evaluation

EVALUATOR_SYSTEM_MESSAGE = """
You are a biomedical evaluator, expert in evaluating biological pathways.

Your task is to evaluate whether a reference biochemical reaction is represented correctly
in a candidate text.

A biochemical reaction can be said to be represented in a candidate text if:

- there is an explicit description of a biological interaction
- the appropriate input entities are present in the interaction. The entities must be specifically referenced
as per the reaction.
For example in the appropriate complex, location and referenced site on the entity.
- the appropriate output entities are present in the interaction. The entities must be specifically referenced
as per the reaction.
For example in the appropriate complex, location and referenced site on the entity.
- the directionality of the reaction is described correctly (i.e. A is affecting B needs to be correct,
but A binds B is symmetric and indifferent as to the order)
- the appropriate reaction type is present.
    - if it is a post-translational modification, it should be described as such,
     e.g. "phosphorylation", "ubiquitination", etc.
    - if it is a binding reaction, it should be described as such.
    Allow synonyms e.g. "binding", "interaction"
    - if it has an explicit sign, it should be described as such,
    e.g. "activates", "inhibits", etc. Accept synonyms like inhibits for downregulates. However do not
    accept if ther reference statement explicitly states a direction (e.g. 'inhibits') and the candidate text
    mention an unsigned relationship like 'regulates'

Assess these criteria individually.

If all criteria are met, return the answer "Yes". If any, but not all, criteria are met,
return "Partially". If no criteria are met, return "No".

If the answer is "Yes or "Partially", extract the evidence from the candidate text that
supports your answer.

Give a brief rationale for your decision.

"""


def evaluate_candidate_against_reference(
    reference_statement: str,
    candidate_text: str,
    seed: int,
) -> TernaryAnswerWithEvidence:
    """
    Evaluate the candidate text against the gold standard reaction description.

    Args:
        reference_statement: The reference statement representing ground-truth biological
         mechanisms.
        candidate_text: The candidate text generated by a hypothesis discovery system.
        seed: Random seed for reproducibility. Defaults to 42.

    Returns:
        A TernaryAnswerWithEvidence containing the evaluation results.

    """
    agent = AssistantAgent(
        name="evaluator",
        system_message=EVALUATOR_SYSTEM_MESSAGE,
        llm_config=gpt4o_ternary_evaluation(seed=seed),
    )

    user_prompt = f"""

        Reference reaction:
        \"\"\"
        {reference_statement}
        \"\"\"

        Candidate text:
        \"\"\"
        {candidate_text}
        \"\"\"

        """

    reply = agent.generate_reply([{"role": "user", "content": user_prompt}])
    content = reply["content"] if isinstance(reply, dict) else reply
    parsed = json.loads(content)
    return TernaryAnswerWithEvidence.model_validate(parsed)
